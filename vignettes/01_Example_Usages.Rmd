---
title: "theoRy: An R package for meta-analyzing theoreticalÂ uncertainty"
output:
  pdf_document:
    fig_width: 4.5
    fig_height: 3
  html_document:
    df_print: paged
classoption: landscape
---
<style type="text/css">
  body{
  font-size: 14pt;
}
</style>

**Authors**: Hung H. V. Nguyen and Nate Breznau. The package is built on top of `dagitty` and `ggdag`. 


**Current version**: 0.1.0

## Setup

To install the package from Github, please use either the remotes (preferable) or devtools

```{r setup, warning = F, message=FALSE}
# install.packages("remotes") ## if remotes does not exist
# remotes::install_github("https://github.com/hungnguyen167/theoRy")
library(theoRy)
library(tidyverse)
library(data.table)
library(gt)
```
\newpage
## Build Causal Matrix (`build_causal_node`)

A causal matrix includes all possible causal configurations of the variables supplied as inputs. When defining the inputs, the user places the variables ordinally in time. Then the algorithm creates every possible causal model, such that every path is either causal or not causal, and simultaneously occurring variables are either not related or are correlated (direction unknown).

### The input arguments:

There are three important input arguments:

1. *nodes* is a list or character vector, where each element is a variable in the model universe. The variables can take any names, but will be transformed into Y, Xtest, and Xn based on their types and timing. 

2. *types* is a list or character vector, where each element is the type of the variables in the model universe. Must be of the same length with the nodes list. This argument takes three values: otc (outcome), test (exposure/test), and ctr (control).

3. *timing* is a list or integer vector (larger is after), where each element is the timing of the variables in the model universe. Must be of the same length with the nodes list. 

\newpage
### Example

The output of the causal matrix has one row per node dyad, and is grouped by model. 


```{r causal_matrix, message=FALSE}

nodes <- c("Y","Xtest","X1","X2")
timing <- c(0,-1,-3,-2)
types <- c("otc","test","ctr","ctr")


causal_matrix <- build_causal_node(nodes = nodes, timing = timing, types=types) 

causal_matrix %>% filter(model==1) %>% gt()



```

\newpage
Notice how there's a column called "user_mod". This means you can enter your biased model(s). If the model is not already in the universe for some reason, you have the option to add. If the model is found, it will be moved to the top.

```{r user_mod, message=FALSE}
user_mods <- c(
    "Y ~ X1 + Xtest; X1 ~ X2",
    "Y ~ Xtest; X2 ~ X1"
)
causal_matrix <- build_causal_node(nodes = nodes, timing = timing, types=types,
                                   user_mods = user_mods)
causal_matrix %>% filter(model %in% c(1,2)) %>% gt()
```

\newpage
Another important feature is to include models where Xs exist but do not have any causal relationships with any other variables. This can be controlled with the include_subsets argument.


```{r include_subsets, message=FALSE}
user_mods <- c(
    "Y ~ Xtest; X1 ~ X1"
)
causal_matrix <- build_causal_node(nodes = nodes, timing = timing, types=types,
                                   include_subsets = TRUE,
                                   user_mods = user_mods)

causal_matrix %>% filter(model==1) %>% gt()
```

\newpage
## Build Formula Matrix (`build_formula_matrix`)

The formula matrix contains lavaan style formulas to express the causal models. This matrix has one model per row. For more information see [lavaan](https://cran.r-project.org/web/packages/lavaan/lavaan.pdf) documentation.

The formula matrix also identifies any minimum adjustment sets (column `mas`) and whether the model is correctly adjusted when all X-variables are adjusted (column `correct_test`). The formula matrix needs two arguments: causal_matrix and node_timing, which can be built using the `build_causal_node` function from above using the argument `return_node=TRUE`

```{r formula_matrix}
causal_matrix <- build_causal_node(nodes,types, timing)
node_timing <- build_causal_node(nodes,types, timing, return_node = TRUE)
formula_matrix <- build_formula_matrix(causal_matrix, node_timing)

formula_matrix %>% filter(model %in% c(1,2)) %>% gt()
```

\newpage
## run_theoRy: the wrapper function

To produce all of the above objects, instead of running through each function, you can (and are recommended) to use the run_theoRy function, which is a wrapper function that will produce the causal_matrix, node_timing, and formula_matrix from the same inputs.

```{r ls_theory}
ls_theory <- run_theoRy(nodes, types, timing)
print(names(ls_theory))
```
\newpage
## Plot DAGs

With this ls_theory object, you can easily plot multiple DAG plots based on model numbers. This function automatically places the variables according to the variables' timing. 

```{r plot_dag}

dag_plots <- plot_dag(ls_theory, choose_plots=c(1:2), save_path="plots/")
dag_plots[[1]]

```

\newpage


The outputs are `ggplot` objects so you can manipulate the plots the same as you manipulate other ggplot objects.
```{r plot_dag_2}

dag_plots[[2]] <- dag_plots[[2]] +
    theme_classic()
dag_plots[[2]]
```
\newpage

## Add compatible

In the working paper coming with this package, we discuss the concepts of test compatible and full-model compatible. To retrieve this information from the model universe, you can use the `add_compatible` function. This is practically choosing a reference model and see how compatible your preferred model is compared to the entire causal model universe. 

```{r add_compatible}
cmp_matrix <- add_compatible(formula_matrix, ref_mod = 1)


cmp_matrix %>% filter(model %in% c(1:10)) %>%  
    select(formula, model, test_compatible, full_model_compatible) %>%
    gt()
```



\newpage
## Other utility functions

There are other utility functions that might be useful for adding/finding models (`find_add_models`) or build a set matrix used in QCA (`build_set_matrix`). You can consult the documentation for further details.

## Future plans

1.  Improve speed
2.  Add more utility functions
3.  Extend to the data processing multiverse
4.  Fit theory with data, then visualise the multiverse
5.  Train a machine learning algorithm to learn how to build the multiverse from any random combination of inputs
